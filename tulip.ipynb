{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barthelemymp/TULIP-TCR/blob/main/tulip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oJiANGCdNplD"
      },
      "outputs": [],
      "source": [
        "local = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RsCjRIQyNpiS",
        "outputId": "7e78b2ad-29f3-4a4e-86f6-5ed6c05da221",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.32.1\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.1) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.1) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.1) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.1) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.1) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.1) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.1) (2.31.0)\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.1) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.1) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.1) (2023.11.17)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, dill, multiprocess, transformers, datasets\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.1\n",
            "    Uninstalling tokenizers-0.15.1:\n",
            "      Successfully uninstalled tokenizers-0.15.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15 tokenizers-0.13.3 transformers-4.32.1\n"
          ]
        }
      ],
      "source": [
        "#@title Clone github repo\n",
        "import json, time, os, sys, glob\n",
        "\n",
        "if not local:\n",
        "  if not os.path.isdir(\"TULIP-TCR\"):\n",
        "    os.system(\"git clone -q https://github.com/barthelemymp/TULIP-TCR.git\")\n",
        "  sys.path.append('/content/TULIP-TCR/')\n",
        "\n",
        "if not local:\n",
        "  !pip install transformers==4.32.1 datasets  tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm-58pdYOmKo",
        "outputId": "de8fd5f3-7672-4477-a9c9-aba0e6dd633e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.24.0\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (2.31.0)\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, pyarrow-hotfix, dill, multiprocess, transformers, datasets\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed datasets-2.16.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6 tokenizers-0.13.3 transformers-4.24.0\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HvtYmEOiOmHm"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\akesh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data._utils.collate import default_collate\n",
        "#from data import TranslationDataset\n",
        "from transformers import BertTokenizerFast, BertTokenizer\n",
        "from transformers import BertModel, BertForMaskedLM, BertConfig, EncoderDecoderModel, BertLMHeadModel, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import os\n",
        "\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertOnlyMLMHead, SequenceClassifierOutput\n",
        "from torch.nn import MSELoss, CrossEntropyLoss, BCEWithLogitsLoss\n",
        "from typing import List, Optional, Tuple, Union\n",
        "from transformers.modeling_outputs import ModelOutput\n",
        "\n",
        "from transformers import PretrainedConfig\n",
        "from transformers.modeling_outputs import BaseModelOutput, Seq2SeqLMOutput\n",
        "from transformers.modeling_utils import PreTrainedModel\n",
        "from transformers.utils import add_start_docstrings, add_start_docstrings_to_model_forward, logging, replace_return_docstrings\n",
        "from transformers.models.encoder_decoder.configuration_encoder_decoder import EncoderDecoderConfig\n",
        "import warnings\n",
        "\n",
        "from src.multiTrans import TulipPetal, TCRDataset, BertLastPooler, unsupervised_auc, train_unsupervised, eval_unsupervised, MyMasking, Tulip, get_logscore\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLQ2Q0h-fFuv"
      },
      "source": [
        "# Load model and file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdKAfHVuU_Jw",
        "outputId": "7ac6c69f-bfb2-474c-a0aa-f4715ceabc5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading hyperparameter\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# filesname = list(uploaded.keys())[0]\n",
        "finetunedmodel = True #@param {type:\"boolean\"}\n",
        "with open(\"configs/shallow.config.json\", \"r\") as read_file:\n",
        "    print(\"loading hyperparameter\")\n",
        "    modelconfig = json.load(read_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcgvjAwSfPzZ"
      },
      "source": [
        "# run prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRGWVReaOmFH",
        "outputId": "7e58445b-b9fc-4140-c0c6-aaf4d959a384"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "55\n",
            "Loading models ..\n",
            "self.pad_token_id 1\n",
            "self.pad_token_id 1\n",
            "self.pad_token_id 1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Tulip(\n",
              "  (encoderA): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30, 128, padding_idx=1)\n",
              "      (position_embeddings): Embedding(50, 128)\n",
              "      (token_type_embeddings): Embedding(1, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-1): 2 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=128, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=128, bias=True)\n",
              "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (decoderA): TulipPetal(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30, 128, padding_idx=1)\n",
              "        (position_embeddings): Embedding(50, 128)\n",
              "        (token_type_embeddings): Embedding(1, 128)\n",
              "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-1): 2 x BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=128, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=128, bias=True)\n",
              "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
              "    (LMcls): BertOnlyMLMHead(\n",
              "      (predictions): BertLMPredictionHead(\n",
              "        (transform): BertPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (transform_act_fn): GELUActivation()\n",
              "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=128, out_features=30, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertLastPooler(\n",
              "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (encoderB): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30, 128, padding_idx=1)\n",
              "      (position_embeddings): Embedding(50, 128)\n",
              "      (token_type_embeddings): Embedding(1, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-1): 2 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=128, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=128, bias=True)\n",
              "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (decoderB): TulipPetal(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30, 128, padding_idx=1)\n",
              "        (position_embeddings): Embedding(50, 128)\n",
              "        (token_type_embeddings): Embedding(1, 128)\n",
              "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-1): 2 x BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=128, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=128, bias=True)\n",
              "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
              "    (LMcls): BertOnlyMLMHead(\n",
              "      (predictions): BertLMPredictionHead(\n",
              "        (transform): BertPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (transform_act_fn): GELUActivation()\n",
              "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=128, out_features=30, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertLastPooler(\n",
              "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (encoderE): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30, 128, padding_idx=1)\n",
              "      (position_embeddings): Embedding(50, 128)\n",
              "      (token_type_embeddings): Embedding(1, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-1): 2 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=128, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=128, bias=True)\n",
              "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (decoderE): TulipPetal(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30, 128, padding_idx=1)\n",
              "        (position_embeddings): Embedding(50, 128)\n",
              "        (token_type_embeddings): Embedding(1, 128)\n",
              "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-1): 2 x BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=128, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=128, bias=True)\n",
              "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
              "    (LMcls): BertOnlyMLMHead(\n",
              "      (predictions): BertLMPredictionHead(\n",
              "        (transform): BertPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (transform_act_fn): GELUActivation()\n",
              "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=128, out_features=30, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertLastPooler(\n",
              "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (MLMHeadA): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=128, out_features=30, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (MLMHeadB): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=128, out_features=30, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (MLMHeadE): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=128, out_features=30, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=384, out_features=2, bias=True)\n",
              "  (mhc_embeddings): Embedding(55, 128)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "checkpoint = torch.load(\"/content/TULIP-TCR/model_weights/pytorch_model.bin\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"aatok/\")\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
        "\n",
        "if tokenizer.sep_token is None:\n",
        "    tokenizer.add_special_tokens({'sep_token': '<MIS>'})\n",
        "\n",
        "if tokenizer.cls_token is None:\n",
        "    tokenizer.add_special_tokens({'cls_token': '<CLS>'})\n",
        "\n",
        "if tokenizer.eos_token is None:\n",
        "    tokenizer.add_special_tokens({'eos_token': '<EOS>'})\n",
        "\n",
        "if tokenizer.mask_token is None:\n",
        "    tokenizer.add_special_tokens({'mask_token': '<MASK>'})\n",
        "\n",
        "\n",
        "\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "tokenizer._tokenizer.post_processor = TemplateProcessing(\n",
        "    single=\"<CLS> $A <EOS>\",\n",
        "    pair=\"<CLS> $A <MIS> $B:1 <EOS>:1\",\n",
        "    special_tokens=[\n",
        "        (\"<EOS>\", 2),\n",
        "        (\"<CLS>\", 3),\n",
        "        (\"<MIS>\", 4),\n",
        "    ],\n",
        ")\n",
        "\n",
        "mhctok = AutoTokenizer.from_pretrained(\"mhctok/\")\n",
        "\n",
        "\n",
        "\n",
        "# mhctok = AutoTokenizer.from_pretrained(\"mhctok/\")\n",
        "\n",
        "vocabsize = len(tokenizer._tokenizer.get_vocab())\n",
        "mhcvocabsize = len(mhctok._tokenizer.get_vocab())\n",
        "print(mhcvocabsize)\n",
        "print(\"Loading models ..\")\n",
        "# vocabsize = encparams[\"vocab_size\"]\n",
        "\n",
        "max_length = 50\n",
        "encoder_config = BertConfig(vocab_size = vocabsize,\n",
        "                    max_position_embeddings = max_length, # this shuold be some large value\n",
        "                    num_attention_heads = modelconfig[\"num_attn_heads\"],\n",
        "                    num_hidden_layers = modelconfig[\"num_hidden_layers\"],\n",
        "                    hidden_size = modelconfig[\"hidden_size\"],\n",
        "                    type_vocab_size = 1,\n",
        "                    pad_token_id =  tokenizer.pad_token_id)\n",
        "\n",
        "encoder_config.mhc_vocab_size  =mhcvocabsize\n",
        "\n",
        "encoderA = BertModel(config=encoder_config)\n",
        "encoderB = BertModel(config=encoder_config)\n",
        "encoderE = BertModel(config=encoder_config)\n",
        "\n",
        "max_length = 100\n",
        "max_length = 50\n",
        "decoder_config = BertConfig(vocab_size = vocabsize,\n",
        "                    max_position_embeddings = max_length, # this shuold be some large value\n",
        "                    num_attention_heads = modelconfig[\"num_attn_heads\"],\n",
        "                    num_hidden_layers = modelconfig[\"num_hidden_layers\"],\n",
        "                    hidden_size = modelconfig[\"hidden_size\"],\n",
        "                    type_vocab_size = 1,\n",
        "                    is_decoder=True,\n",
        "                    pad_token_id =  tokenizer.pad_token_id)    # Very Important\n",
        "\n",
        "decoder_config.add_cross_attention=True\n",
        "\n",
        "decoderA = TulipPetal(config=decoder_config) #BertForMaskedLM\n",
        "decoderA.pooler = BertLastPooler(config=decoder_config)\n",
        "decoderB = TulipPetal(config=decoder_config) #BertForMaskedLM\n",
        "decoderB.pooler = BertLastPooler(config=decoder_config)\n",
        "decoderE = TulipPetal(config=decoder_config) #BertForMaskedLM\n",
        "decoderE.pooler = BertLastPooler(config=decoder_config)\n",
        "\n",
        "\n",
        "# Define encoder decoder model\n",
        "model = Tulip(encoderA=encoderA,encoderB=encoderB,encoderE=encoderE, decoderA=decoderA, decoderB=decoderB, decoderE=decoderE)\n",
        "\n",
        "model.load_state_dict(checkpoint)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogkZ_4yVdQ7l",
        "outputId": "d6011e88-8ac0-4069-a620-8cf3118dbb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.32.1\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wrPnrsTDO4mg"
      },
      "outputs": [],
      "source": [
        "filesname = \"data/VDJ_test_2.csv\"\n",
        "compute_auc=True\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgVmDdT6e6D5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qetoCbz8O4jw",
        "outputId": "305f8065-8d89-4689-daf4-a75e3f12c048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading the data ...\n",
            "GILGFVFTL\n",
            "(0.691439842209073, 0.8354319526627219, 0.9531092702169626)\n",
            "0.9531092702169626\n",
            "Loading the data ...\n",
            "LLWNGPMAV\n",
            "(0.5719838955990559, 0.6018325697625988, 0.8771345272803)\n",
            "0.8771345272803\n",
            "Loading the data ...\n",
            "CINGVCWTV\n",
            "(0.44986127625842254, 0.28418549346016647, 0.8006341656757828)\n",
            "0.8006341656757828\n",
            "Loading the data ...\n",
            "ELAGIGILTV\n",
            "(0.6580569727891157, 0.5020727040816326, 0.9071003401360545)\n",
            "0.9071003401360545\n",
            "Loading the data ...\n",
            "WLLWPVTLA\n",
            "(0.08333333333333337, 0.375, 0.5416666666666666)\n",
            "0.5416666666666666\n",
            "Loading the data ...\n",
            "NLVPMVATV\n",
            "(0.4566615226337448, 0.4154449588477367, 0.7861689814814814)\n",
            "0.7861689814814815\n",
            "Loading the data ...\n",
            "YLQPRTFLL\n",
            "(0.6640946502057613, 0.618427069044353, 0.8885459533607681)\n",
            "0.8885459533607681\n",
            "Loading the data ...\n",
            "SLFNTVATLY\n",
            "(0.6292517006802721, 0.3299319727891156, 0.7040816326530612)\n",
            "0.7040816326530612\n",
            "Loading the data ...\n",
            "RMFPNAPYL\n",
            "(0.25, 0.45833333333333337, 0.75)\n",
            "0.75\n",
            "Loading the data ...\n",
            "TLLFLMSFT\n",
            "(0.20833333333333331, 0.41666666666666663, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "LLYDANYFL\n",
            "(0.3945578231292517, 0.6428571428571429, 0.8129251700680272)\n",
            "0.8129251700680272\n",
            "Loading the data ...\n",
            "GLCTLVAML\n",
            "(0.6078191133882824, 0.5869161654414494, 0.9181703423182594)\n",
            "0.9181703423182594\n",
            "Loading the data ...\n",
            "ALWEIQQVV\n",
            "(0.35374149659863946, 0.2755102040816326, 0.7040816326530612)\n",
            "0.7040816326530612\n",
            "Loading the data ...\n",
            "RLCAYCCNI\n",
            "(0.33333333333333337, 0.0, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "FVAAIFYLI\n",
            "(0.16666666666666663, 0.16666666666666663, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "FLASKIGRLV\n",
            "(0.3333333333333333, 0.375, 0.71875)\n",
            "0.71875\n",
            "Loading the data ...\n",
            "LLFNKVTLA\n",
            "(0.8333333333333334, 0.8333333333333334, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "HLMSFPQSA\n",
            "(0.6666666666666667, 0.41666666666666663, 0.25)\n",
            "0.25\n",
            "Loading the data ...\n",
            "YLNTLTLAV\n",
            "(0.0, 0.5, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "ILGFVFTLT\n",
            "(0.29166666666666663, 0.2916666666666667, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "KLQFTSLEI\n",
            "(0.16666666666666663, 0.6666666666666667, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "CLEASFNYL\n",
            "(0.33333333333333337, 0.16666666666666663, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "FLYALALLL\n",
            "(0.8593749999999999, 0.8098958333333333, 0.9765625)\n",
            "0.9765625\n",
            "Loading the data ...\n",
            "KLQCVDLHV\n",
            "(0.5, 0.16666666666666663, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "IMDQVPFSV\n",
            "(0.6666666666666667, 0.0, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "NLNCCSVPV\n",
            "(0.16666666666666663, 1.0, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "KVYPIILRL\n",
            "(0.5833333333333333, 0.33333333333333337, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "KQLSSNFGA\n",
            "(0.6666666666666667, 1.0, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "KQIYKTPPI\n",
            "(0.16666666666666663, 0.16666666666666663, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "TLIGDCATV\n",
            "(0.5, 0.16666666666666663, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "VLNDILSRL\n",
            "(0.0, 0.16666666666666663, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "GLALYYPSA\n",
            "(0.16666666666666663, 0.5, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "FLPRVFSAV\n",
            "(0.4583333333333333, 0.38541666666666663, 0.6458333333333334)\n",
            "0.6458333333333334\n",
            "Loading the data ...\n",
            "NLIDSYFVV\n",
            "(0.33333333333333337, 0.0, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "LPDDFMGCV\n",
            "(0.33333333333333337, 0.0, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "WLDMVDTSL\n",
            "(0.08333333333333331, 0.5, 0.7916666666666666)\n",
            "0.7916666666666666\n",
            "Loading the data ...\n",
            "LLFGYPVYV\n",
            "(0.3958333333333333, 0.47916666666666663, 0.8333333333333333)\n",
            "0.8333333333333333\n",
            "Loading the data ...\n",
            "ALSKGVHFV\n",
            "(0.46296296296296297, 0.18518518518518517, 0.7777777777777778)\n",
            "0.7777777777777778\n",
            "Loading the data ...\n",
            "FLPGVYSVI\n",
            "(1.0, 0.6666666666666667, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "YVWKSYVHV\n",
            "(0.6666666666666667, 0.33333333333333337, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "KLVAMGINAV\n",
            "(0.5, 0.462962962962963, 0.8703703703703705)\n",
            "0.8703703703703705\n",
            "Loading the data ...\n",
            "KLFIRQEEV\n",
            "(0.5, 1.0, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "KLPDDFMGC\n",
            "(0.5, 0.16666666666666663, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "RLARLALVL\n",
            "(0.5833333333333333, 0.375, 0.5833333333333333)\n",
            "0.5833333333333333\n",
            "Loading the data ...\n",
            "AAGIGILTV\n",
            "(0.33333333333333337, 0.8333333333333334, 0.33333333333333337)\n",
            "0.33333333333333337\n",
            "Loading the data ...\n",
            "LLLEWLAMA\n",
            "(0.5, 0.0, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "LMWLSYFIA\n",
            "(0.16666666666666663, 0.16666666666666663, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "TALALLLLD\n",
            "(1.0, 0.16666666666666663, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "MLDLQPETT\n",
            "(0.6666666666666667, 0.5, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "KLWAQCVQL\n",
            "(0.6666666666666667, 0.6666666666666667, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "KLKDCVMYA\n",
            "(0.16666666666666663, 0.16666666666666663, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "ALDPHSGHFV\n",
            "(1.0, 1.0, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "LLDFVRFMGV\n",
            "(0.2708333333333333, 0.38541666666666663, 0.8333333333333334)\n",
            "0.8333333333333333\n",
            "Loading the data ...\n",
            "QVVSDIDYV\n",
            "(0.33333333333333337, 0.16666666666666663, 0.33333333333333337)\n",
            "0.33333333333333337\n",
            "Loading the data ...\n",
            "FTVLCLTPV\n",
            "(0.0, 0.16666666666666663, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "LIDFYLCFL\n",
            "(0.5, 0.33333333333333337, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "FLNRFTTTL\n",
            "(0.75, 0.0, 0.7916666666666666)\n",
            "0.7916666666666666\n",
            "Loading the data ...\n",
            "YIDIGDYTV\n",
            "(0.45833333333333337, 0.29166666666666663, 0.7916666666666667)\n",
            "0.7916666666666667\n",
            "Loading the data ...\n",
            "RLGPVQNEV\n",
            "(0.375, 0.5416666666666667, 0.5833333333333333)\n",
            "0.5833333333333333\n",
            "Loading the data ...\n",
            "IKLDDKDPQ\n",
            "(0.8333333333333334, 0.0, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "ALYGFVPVL\n",
            "(0.041666666666666685, 0.5416666666666667, 0.625)\n",
            "0.625\n",
            "Loading the data ...\n",
            "FLHVTYVPA\n",
            "(0.33333333333333337, 0.2962962962962963, 0.7592592592592593)\n",
            "0.7592592592592593\n",
            "Loading the data ...\n",
            "KMDYFSGQL\n",
            "(0.5, 0.5, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "RLPGVLPRA\n",
            "(0.4583333333333333, 0.46759259259259256, 0.587962962962963)\n",
            "0.587962962962963\n",
            "Loading the data ...\n",
            "YVDNSSLTI\n",
            "(0.8333333333333334, 0.0, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "DQVILLNKH\n",
            "(0.0, 1.0, 0.16666666666666663)\n",
            "0.16666666666666663\n",
            "Loading the data ...\n",
            "TMCDIRQLL\n",
            "(0.0, 0.0, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "YLLEMLWRL\n",
            "(0.33333333333333337, 0.6666666666666667, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "SLLMWITQV\n",
            "(0.16666666666666663, 0.6666666666666667, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "FLCLFLLPS\n",
            "(0.5, 0.16666666666666663, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "DRLNQLESK\n",
            "(0.16666666666666663, 0.0, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "FVVFLLVTL\n",
            "(0.0, 0.33333333333333337, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "SMWALVISV\n",
            "(0.16666666666666663, 0.0, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "YLNSTNVTI\n",
            "(0.6666666666666667, 0.0, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "SLLSVLLSM\n",
            "(0.5, 0.33333333333333337, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "FLLPSLATV\n",
            "(0.0, 0.33333333333333337, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "IMLCCMTSC\n",
            "(0.0, 0.0, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "YADVFHLYL\n",
            "(0.33333333333333337, 0.16666666666666663, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "RLFARTRSM\n",
            "(0.8333333333333334, 0.0, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "KLFEFLVYGV\n",
            "(0.5, 0.8333333333333334, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "VLWAHGFEL\n",
            "(0.33333333333333337, 0.33333333333333337, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "DLFMRIFTI\n",
            "(0.16666666666666663, 0.5, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "AVIKTLQPV\n",
            "(0.6666666666666667, 0.6666666666666667, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "RTLNAWVKV\n",
            "(0.2312925170068027, 0.3945578231292517, 0.6938775510204082)\n",
            "0.6938775510204082\n",
            "Loading the data ...\n",
            "YLNDHLEPWI\n",
            "(0.5833333333333334, 0.08333333333333337, 0.75)\n",
            "0.75\n",
            "Loading the data ...\n",
            "VMVELVAEL\n",
            "(0.33333333333333326, 0.37037037037037035, 0.7037037037037037)\n",
            "0.7037037037037037\n",
            "Loading the data ...\n",
            "SLINTLNDL\n",
            "(0.0, 0.0, 0.16666666666666663)\n",
            "0.16666666666666663\n",
            "Loading the data ...\n",
            "KSVNITFEL\n",
            "(0.2962962962962963, 0.11111111111111108, 0.7037037037037037)\n",
            "0.7037037037037037\n",
            "Loading the data ...\n",
            "AIFYLITPV\n",
            "(0.16666666666666663, 0.16666666666666663, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "LMGHFAWWT\n",
            "(0.0, 0.16666666666666663, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "KDNVILLNK\n",
            "(0.5, 0.0, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "RTIKVFTTV\n",
            "(0.8333333333333334, 0.8333333333333334, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "QMAPISAMV\n",
            "(0.33333333333333337, 0.16666666666666663, 0.16666666666666663)\n",
            "0.16666666666666663\n",
            "Loading the data ...\n",
            "YMPYFFTLL\n",
            "(0.41666666666666663, 0.20833333333333331, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "SACVLAAEC\n",
            "(0.33333333333333337, 0.6666666666666667, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "YTVSCLPFT\n",
            "(0.33333333333333337, 0.6666666666666667, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "FLIGCNYLG\n",
            "(0.8333333333333334, 0.0, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "SLENVAFNV\n",
            "(0.5, 0.6666666666666667, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "SLPGVFCGV\n",
            "(0.6666666666666667, 0.6666666666666667, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "KLNIKLLGV\n",
            "(0.33333333333333337, 0.33333333333333337, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "WLTNIFGTV\n",
            "(0.8333333333333334, 0.0, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "LITGRLQSL\n",
            "(0.5, 0.6666666666666667, 0.5)\n",
            "0.5\n",
            "Loading the data ...\n",
            "MMILSDDAV\n",
            "(0.125, 0.6666666666666667, 0.9166666666666667)\n",
            "0.9166666666666667\n",
            "Loading the data ...\n",
            "KLNEEIAII\n",
            "(0.8333333333333334, 0.33333333333333337, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "NLHPDSATL\n",
            "(0.0, 0.5, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "SWMESEFRV\n",
            "(0.0, 0.0, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "KLSYGIATV\n",
            "(0.16666666666666669, 0.375, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "EAAGIGILTV\n",
            "(0.5104166666666666, 0.8125, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "ALLPGLPAA\n",
            "(0.16666666666666663, 0.5, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "CVNGSCFTV\n",
            "(0.375, 0.7083333333333334, 0.5833333333333334)\n",
            "0.5833333333333334\n",
            "Loading the data ...\n",
            "ALYYPSARI\n",
            "(0.16666666666666663, 0.0, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "CLAVHECFV\n",
            "(0.0, 0.5, 0.8333333333333333)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "SVLYYQNNV\n",
            "(0.5, 0.16666666666666663, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "VLLGVKLFGV\n",
            "(0.5, 0.0, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "ILAYCNKTV\n",
            "(0.33333333333333337, 0.8333333333333334, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "MQVESDDYI\n",
            "(0.6666666666666667, 0.0, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "FLNGSCGSV\n",
            "(0.16666666666666663, 0.0, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "FLAHIQWMV\n",
            "(0.33333333333333337, 0.16666666666666663, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "HMTEVVRHC\n",
            "(0.0, 0.0, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "KVLEYVIKV\n",
            "(0.375, 0.16666666666666669, 0.7083333333333333)\n",
            "0.7083333333333333\n",
            "Loading the data ...\n",
            "FLLNKEMYL\n",
            "(0.33333333333333337, 0.875, 0.75)\n",
            "0.75\n",
            "Loading the data ...\n",
            "RIMTWLDMV\n",
            "(0.25, 0.29166666666666663, 0.5416666666666666)\n",
            "0.5416666666666666\n",
            "Loading the data ...\n",
            "SMMILSDDA\n",
            "(0.5, 0.16666666666666663, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "AMQTMLFTM\n",
            "(0.4583333333333333, 0.875, 0.9166666666666666)\n",
            "0.9166666666666666\n",
            "Loading the data ...\n",
            "TLEYMDWLV\n",
            "(0.6666666666666667, 0.0, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "KLSALGINAV\n",
            "(0.5, 0.33333333333333337, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "KIILFLALI\n",
            "(0.16666666666666663, 0.6666666666666666, 0.33333333333333337)\n",
            "0.33333333333333337\n",
            "Loading the data ...\n",
            "SLLMPILTL\n",
            "(0.8333333333333334, 0.33333333333333337, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "YLGGMSYYC\n",
            "(0.8333333333333334, 0.16666666666666663, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "FIAGLIAIV\n",
            "(0.6666666666666666, 0.4583333333333333, 0.7916666666666667)\n",
            "0.7916666666666667\n",
            "Loading the data ...\n",
            "QVILLNKHI\n",
            "(0.33333333333333337, 0.8333333333333334, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "YMRSLKVPA\n",
            "(0.6666666666666667, 0.5, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "IQPGQTFSV\n",
            "(0.8333333333333334, 0.16666666666666663, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "RLYLDAYNM\n",
            "(0.6666666666666667, 0.6666666666666667, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "KLYGLDWAEL\n",
            "(0.33333333333333337, 0.16666666666666663, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "SGGGETALA\n",
            "(0.6666666666666667, 0.6666666666666667, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "KLPDDFTGCV\n",
            "(0.33333333333333337, 0.0, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "NVLTLVYKV\n",
            "(0.33333333333333337, 0.6666666666666667, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "MLNPNYEDL\n",
            "(0.0, 0.16666666666666663, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "LLLTILTSL\n",
            "(0.33333333333333337, 0.0, 0.33333333333333337)\n",
            "0.33333333333333337\n",
            "Loading the data ...\n",
            "KLIEYTDFA\n",
            "(0.0, 0.33333333333333337, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "ALNTPKDHI\n",
            "(0.0, 1.0, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "TLMNVITLV\n",
            "(0.16666666666666663, 0.33333333333333337, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "KTWGQYWQV\n",
            "(0.8333333333333334, 0.8333333333333334, 0.6666666666666667)\n",
            "0.6666666666666667\n",
            "Loading the data ...\n",
            "TILTSLLVL\n",
            "(0.8333333333333334, 0.5, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "VFLVLLPLV\n",
            "(0.8333333333333334, 0.16666666666666663, 1.0)\n",
            "1.0\n",
            "Loading the data ...\n",
            "FLALCADSI\n",
            "(0.16666666666666663, 0.5, 0.8333333333333334)\n",
            "0.8333333333333334\n",
            "Loading the data ...\n",
            "YGFQPTNGV\n",
            "(0.8333333333333334, 0.5, 0.8333333333333334)\n",
            "0.8333333333333334\n"
          ]
        }
      ],
      "source": [
        "target_peptidesFinal = pd.read_csv(filesname)[\"peptide\"].unique()\n",
        "\n",
        "for target_peptide in target_peptidesFinal:\n",
        "    results = pd.DataFrame(columns=[\"CDR3a\", \"CDR3b\", \"peptide\", \"rank\"])\n",
        "    datasetPetideSpecific= TCRDataset(filesname, tokenizer, device,target_peptide=target_peptide, mhctok=mhctok)\n",
        "    print(target_peptide)\n",
        "    scores = -1*np.array(get_logscore(datasetPetideSpecific, model, ignore_index =  tokenizer.pad_token_id))\n",
        "    ranks = np.argsort(np.argsort(scores))\n",
        "    results[\"CDR3a\"] = datasetPetideSpecific.alpha\n",
        "    results[\"CDR3b\"] = datasetPetideSpecific.beta\n",
        "    results[\"peptide\"] = target_peptide\n",
        "    results[\"rank\"] = ranks\n",
        "    # print(results)\n",
        "    if compute_auc:\n",
        "      dl = torch.utils.data.DataLoader(dataset=datasetPetideSpecific, batch_size=1, shuffle=False, collate_fn=datasetPetideSpecific.all2allmhc_collate_function)\n",
        "      print(unsupervised_auc(model,dl, tokenizer.pad_token_id))\n",
        "      auce = roc_auc_score(datasetPetideSpecific.binder, ranks)\n",
        "      print(auce)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKa3opZiO4hQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}